{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "\n",
    "#drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "PATH = Path('../data')\n",
    "#PATH = Path('/content/gdrive/My Drive/ml-practico/data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data\n",
    "\n",
    "Con lo que aprendimos del notebook anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py:3062: DtypeWarning: Columns (5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "title_basics = pd.read_csv(PATH / 'title.basics.tsv', sep='\\t')\n",
    "\n",
    "movie_gross = pd.read_csv(PATH / 'movie_gross.csv')\n",
    "# Calculamos el id de pelicula\n",
    "movie_gross['tconst'] = movie_gross.movie_imdb_link.apply(lambda x: x.split('/')[4])\n",
    "# Deduplicamos los registros\n",
    "movie_gross = movie_gross.groupby('tconst').gross.max().reset_index()\n",
    "\n",
    "title_ratings = pd.read_csv(PATH / 'title.ratings.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           1\n",
       "1           5\n",
       "2           4\n",
       "3          12\n",
       "4           1\n",
       "           ..\n",
       "7156875    \\N\n",
       "7156876    \\N\n",
       "7156877    \\N\n",
       "7156878    27\n",
       "7156879    10\n",
       "Name: runtimeMinutes, Length: 7156880, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_basics.runtimeMinutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'isdigit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-db6e35e926e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Convertimos runtimeMinutes a float. No se puede tener una columna de tipo int con NaN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m title_basics.runtimeMinutes = (\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtitle_basics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mruntimeMinutes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdigit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4210\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4211\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4212\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-db6e35e926e5>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Convertimos runtimeMinutes a float. No se puede tener una columna de tipo int con NaN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m title_basics.runtimeMinutes = (\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtitle_basics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mruntimeMinutes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdigit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'isdigit'"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "from collections import Counter\n",
    "\n",
    "def parse_genres(genres):\n",
    "    if isinstance(genres, float) or genres == r'\\N': return ['no-genre']\n",
    "    else: return genres.split(',')\n",
    "    \n",
    "\n",
    "# Convertimos runtimeMinutes a float. No se puede tener una columna de tipo int con NaN\n",
    "title_basics.runtimeMinutes = (\n",
    "    title_basics.runtimeMinutes.apply(lambda x: np.nan if not x.isdigit() else x).astype(float)\n",
    ")\n",
    "\n",
    "title_basics['genres'] = title_basics.genres.apply(parse_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_basics = title_basics[\n",
    "    # Dejamos tvSpecial, video y tvMovie por ahora, vamos a ver de que se tratan\n",
    "    ~title_basics.titleType.isin(['tvEpisode', 'tvSeries', 'tvMiniSeries', 'videoGame', 'tvShort', 'short'])\n",
    "    # Que tengan valor de runtimeMinutes\n",
    "    & ~title_basics.runtimeMinutes.isna()\n",
    "    # Menos de 3 horas y media para no descartar a titanic\n",
    "    & (title_basics.runtimeMinutes <= 3.5 * 60)\n",
    "    # Descartamos los shorts\n",
    "    & title_basics.genres.apply(lambda x: 'Short' not in x)\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Juntamos todo\n",
    "\n",
    "movies = (\n",
    "    title_basics.merge(movie_gross, on='tconst', how='left')\n",
    "                .merge(title_ratings, on='tconst', how='left')\n",
    ")\n",
    "\n",
    "len(movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check\n",
    "\n",
    "Se ve igual que en el notebook anterior?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.runtimeMinutes.hist(bins=40);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Miremos un caso individual (titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies[movies.tconst == 'tt0120338']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HipÃ³tesis: el rating es buen predictor del gross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only gross and rating data frame\n",
    "ogr_df = movies.dropna(subset=['averageRating', 'numVotes', 'gross']).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ogr_df.plot.scatter('numVotes', 'averageRating', alpha=0.25)\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ogr_df['log(numVotes)'] = np.log10(ogr_df.numVotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ogr_df.plot.scatter('averageRating', 'gross', c='log(numVotes)', cmap='Reds', alpha=0.25, figsize=(7,5))\n",
    "plt.yscale('log');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No parece haber una correlacion directa, pero parece haber dos clusters diferenciados. PodrÃ¡n explicarse con algun genero, u otra columna de los datos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    ogr_df[ogr_df.genres.apply(lambda x: 'Thriller'  in x)]\n",
    "    .plot.scatter('averageRating', 'gross', c='log(numVotes)', cmap='Reds', alpha=0.25, figsize=(7,5))\n",
    ")\n",
    "plt.yscale('log');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HabrÃ¡ mas como estos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HabrÃ¡ bias en la data que tiene gross?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ogr_df.averageRating.plot.density(bw_method=0.5)\n",
    "movies[~movies.averageRating.isna()].averageRating.plot.density(bw_method=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot([ogr_df.averageRating, movies[~movies.averageRating.isna()].averageRating]);\n",
    "plt.xticks([1, 2], ['ogr', 'all movies'])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si miramos numVotes, si hay una diferencia grande"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot([np.log10(ogr_df.numVotes), np.log10(movies[~movies.averageRating.isna()].numVotes)]);\n",
    "plt.xticks([1, 2], ['ogr', 'all movies'])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pareciera que las colas de la distribucion no estan bien representadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tiene sentido plantarlo como clasificacion: P(gross > X dollars)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log10(ogr_df.gross).plot.density(bw_method=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece haber un **sesgo grande** en la eleccion de las peliculas de movies_gross como para utilizarla para este proposito\n",
    "\n",
    "Volvemos con el equipo de negocio y les proponemos predecir el rating como proxy. Se sienten comodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Si utilizamos la probabilidad de que reciba al menos un rating de X?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.dropna(subset=['averageRating']).averageRating.plot.density(bw_method=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La distribucion es amplia, parece ser interesante\n",
    "np.percentile(movies.averageRating.dropna(), [25, 50, 75, 85, 95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ¤” Para pensar \n",
    "\n",
    "Cuantos votos tiene que tener una pelicula para usarla en training / testing?\n",
    "\n",
    "QuÃ© metrica usamos? \n",
    "* Accuracy? \n",
    "* ROC AUC?\n",
    "* f1?\n",
    "* Otra?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test set split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['startYear'] = movies['startYear'].apply(lambda x: np.nan if x == r'\\N' else int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.groupby('startYear').tconst.agg('count').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies[movies.startYear > 1970].dropna(subset=['averageRating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = movies[movies.startYear <= 2017]\n",
    "test_df = movies[movies.startYear > 2017]\n",
    "\n",
    "len(train_df), len(test_df), len(test_df) / len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = (train_df.averageRating >= 7.4).values\n",
    "y_test = (test_df.averageRating >= 7.4).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.sum() / len(y_train), y_test.sum() / len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering 101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hay relacion entre el genero y la pelicula?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a usar todo como listas de diccionarios para poder usar el ecosistema de sklearn de forma sencilla\n",
    "\n",
    "train_docs = train_df.to_dict(orient='records')\n",
    "test_docs = test_df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class GenreDummies(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y): return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        res = []\n",
    "        for e in X:\n",
    "            res.append({g: 1 for g in e['genres']})\n",
    "        return res        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def test_pipe(pipe):\n",
    "    return {\n",
    "        'train_auc': roc_auc_score(y_train, pipe.predict_proba(train_docs)[:, 1]),\n",
    "        'test_auc': roc_auc_score(y_test, pipe.predict_proba(test_docs)[:, 1])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(\n",
    "    GenreDummies(), DictVectorizer(sparse=False), StandardScaler(), LogisticRegression()\n",
    ")\n",
    "\n",
    "pipe.fit(train_docs, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pipe(pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CÃ³mo controlamos por el aÃ±o?\n",
    "\n",
    "Tiene sentido?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class YearsAgo(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.now = datetime.now().year\n",
    "        \n",
    "    def fit(self, X, y): return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        res = []\n",
    "        for e in X:\n",
    "            res.append({'years_ago': self.now - int(e['startYear'])})\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_union\n",
    "\n",
    "pipe = make_pipeline(\n",
    "    make_union(\n",
    "        make_pipeline(YearsAgo(), DictVectorizer(sparse=False)),\n",
    "        make_pipeline(GenreDummies(), DictVectorizer(sparse=False))\n",
    "    ),\n",
    "    StandardScaler(),\n",
    "    LogisticRegression()\n",
    ")\n",
    "\n",
    "pipe.fit(train_docs, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pipe(pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No afecta mucho la metrica.\n",
    "\n",
    "**Challenge**: esto realmente controla algo? sirve para algo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CÃ³mo podemos incorporar informaciÃ³n de la crew?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crew_df = pd.read_csv(PATH / 'title.crew.tsv', sep='\\t')\n",
    "principals_df = pd.read_csv(PATH / 'title.principals.tsv', sep='\\t')\n",
    "names_df = pd.read_csv(PATH / 'title.basics.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crew_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "principals_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "principals_df.category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En las peliculas hay mas de un director\n",
    "\n",
    "El director puede estar en ordering random \n",
    "\n",
    "ejemplos tt4898864 (10 directores)\n",
    "\n",
    "titanic tt0120338 director en ordering 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Me quedo solo con los que fueron directores\n",
    "movies_directors = principals_df[principals_df.category == 'director'].copy()\n",
    "# Calculo un ranking por pelicula segun el ordering\n",
    "movies_directors['director_rank'] = (\n",
    "    movies_directors.sort_values('ordering')\n",
    "                    .groupby('tconst')\n",
    "                    .cumcount()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Me quedo con el \"director principal\" por pelicula\n",
    "movies_directors = movies_directors[movies_directors.director_rank == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check, no deberÃ­a haber repetidos\n",
    "movies_directors.tconst.value_counts().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# me quedo solo con la columna del director\n",
    "movies_directors = (\n",
    "    movies_directors.rename(columns={'nconst': 'director'})\n",
    "    [['tconst', 'director']]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_directors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.merge(movies_directors, on='tconst', how='left').fillna('-')\n",
    "test_df = test_df.merge(movies_directors, on='tconst', how='left').fillna('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "director_movies_distr = (\n",
    "    train_df[train_df.director != '-']\n",
    "            .director\n",
    "            .value_counts()\n",
    "            .value_counts()\n",
    "            .sort_index()\n",
    ")\n",
    "\n",
    "director_movies_distr.plot(style='-o', logx=True, logy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(director_movies_distr.cumsum() / director_movies_distr.sum()).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_df.director == '-').sum() / len(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El 9% de los casos no tenemos info del director.\n",
    "\n",
    "La mayoria (64%) de los directores hicieron una peli nada mas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: como se ve titanic?\n",
    "train_df[train_df.tconst == 'tt0120338']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_df.director.value_counts() >= 2).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer & experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class DirectorFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, min_cnt_movies = 2):\n",
    "        self.min_cnt_movies = min_cnt_movies\n",
    "        \n",
    "    def fit(self, X, y): \n",
    "        # Esto no es la forma mas elegante, pero es mas comodo y a esta altura priorizo la comodidad\n",
    "        # Llevamos las cosas de nuevo a un DataFrame y calculamos features por director\n",
    "        directors_stats = (\n",
    "            pd.DataFrame(X)\n",
    "              .groupby('director')\n",
    "              .agg({\n",
    "                  'tconst': 'count', \n",
    "                  'averageRating': ['mean', 'max', 'min'], \n",
    "                  'numVotes': ['mean', 'min', 'max']}\n",
    "              )\n",
    "        )\n",
    "        \n",
    "        # Para hacer flattening de las columnas\n",
    "        # https://stackoverflow.com/questions/14507794/pandas-how-to-flatten-a-hierarchical-index-in-columns\n",
    "        directors_stats.columns = [\n",
    "            '_'.join(i) \n",
    "            for i in zip(directors_stats.columns.get_level_values(1), directors_stats.columns.get_level_values(0))\n",
    "        ]\n",
    "        \n",
    "        # Guardamos las estadisticas\n",
    "        self.directors_stats_ = directors_stats\n",
    "        \n",
    "        # Diccionario con los datos para los directores comunes\n",
    "        self.directors_stats_lk_ = (\n",
    "            directors_stats[directors_stats.count_tconst >= self.min_cnt_movies].to_dict(orient='index')\n",
    "        )\n",
    "        \n",
    "        # Valor default para los que consideramos que tenemos demasiado poca data\n",
    "        self.default_ = directors_stats[directors_stats.count_tconst < self.min_cnt_movies].mean(0).to_dict()\n",
    "        if self.min_cnt_movies > 1:\n",
    "            self.default_ = directors_stats[directors_stats.count_tconst < self.min_cnt_movies].mean(0).to_dict()\n",
    "        else:\n",
    "            self.default_ = directors_stats.mean(0).to_dict()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        res = []\n",
    "        for e in X:\n",
    "            if e['director'] in self.directors_stats_lk_:\n",
    "                res.append(self.directors_stats_lk_[e['director']])\n",
    "            else:\n",
    "                res.append(self.default_)\n",
    "        return res            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_docs = train_df.to_dict(orient='records')\n",
    "test_docs = test_df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(\n",
    "    DirectorFeatures(), DictVectorizer(sparse=False), StandardScaler(), LogisticRegression()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(train_docs, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pipe(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_union\n",
    "\n",
    "pipe = make_pipeline(\n",
    "    make_union(\n",
    "        make_pipeline(YearsAgo(), DictVectorizer(sparse=False)),\n",
    "        make_pipeline(GenreDummies(), DictVectorizer(sparse=False)),\n",
    "        make_pipeline(DirectorFeatures(min_cnt_movies=4), DictVectorizer(sparse=False))\n",
    "    ),\n",
    "    StandardScaler(),\n",
    "    LogisticRegression()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(train_docs, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pipe(pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Para seguir\n",
    "\n",
    "* Como podes explotar aÃºn mas el cast and crew?\n",
    "* Como podes manejar el caso donde no sabemos mucho sobre el director? Esta bien min_count=2? deberÃ­a ser mayor? menor?\n",
    "* QuÃ© otras familias de modelos no-lineales podemos probar?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
